{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d5e5d4",
   "metadata": {},
   "source": [
    "# Understanding Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d2785a",
   "metadata": {},
   "source": [
    "##\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c7e2f",
   "metadata": {},
   "source": [
    "## üìö  Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "Welcome to this comprehensive guide on **embeddings** - one of the fundamental concepts in modern natural language processing and machine learning.\n",
    "\n",
    "### What Are Embeddings?\n",
    "\n",
    "Embeddings are high-dimensional **vector representations** of text that transform words, sentences, or documents into numerical arrays that capture semantic meaning->\n",
    "\n",
    "**Key Properties:**\n",
    "- Similar meanings -> closer vectors in space\n",
    "- Different meanings -> vectors farther apart\n",
    "- Used in: semantic search, clustering, classification, and RAG systems\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a17580",
   "metadata": {},
   "source": [
    "##\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3fe3e",
   "metadata": {},
   "source": [
    "## üé® A Simple 2D World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toy_example",
   "metadata": {},
   "source": [
    "To understand embeddings intuitively, let's imagine a simplified **2-dimensional world** with two axes:\n",
    "\n",
    "- **X-axis = Fruit-ness** (how much the word relates to fruits)\n",
    "- **Y-axis = Sweetness** (how sweet the item is)\n",
    "\n",
    "### Example Mappings\n",
    "\n",
    "| Word | Coordinates | Quadrant |\n",
    "|------|-------------|----------|\n",
    "| üçé apple | (0.9, 0.7) | 1st |\n",
    "| üçå banana | (0.5, 0.8) | 1st |\n",
    "| üíª operating system | (-0.2, -0.4) | 3rd |\n",
    "\n",
    "Both **apple** and **banana** lie in the first quadrant because they're fruits with sweetness. The **operating system** is in a completely different region since it's neither a fruit nor sweet.\n",
    "\n",
    "![Embedding Space](../../data/photos/embedding_space.png)\n",
    "\n",
    "> **Note:** While this example uses 2 dimensions for visualization, real-world embedding models typically operate in much higher dimensions (384-1024+) to capture complex relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76496056",
   "metadata": {},
   "source": [
    "##\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637111dc",
   "metadata": {},
   "source": [
    "## üìê Measuring Similarity: The Distance Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed559d",
   "metadata": {},
   "source": [
    "Now that we've introduced embeddings, let's talk about how we use them in practice. Embeddings have a wide range of applications: clustering, classification, semantic search, and more. From a RAG perspective, embeddings help us retrieve information that's similar to or shares meaning with the user's query.\n",
    "\n",
    "But how exactly do we measure how similar two pieces of text are using embeddings? Let's try out a few approaches.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6ee554",
   "metadata": {},
   "source": [
    "### First Approach: Quadrant-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac20fe6",
   "metadata": {},
   "source": [
    "**Intuition:** They are in the same quadrant... so they must be similar?? <br><br>\n",
    "Apple and banana both lie in the first quadrant, so they must be similar while Operating system is in the opposite quadrant, so it feels unrelated.\n",
    "\n",
    "**Problem:** This gives us a very rough sense of similarity, but it's not sensitive enough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c06e16",
   "metadata": {},
   "source": [
    "###\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02c60e1",
   "metadata": {},
   "source": [
    "### Second Approach: Euclidean Distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similarity_intro",
   "metadata": {},
   "source": [
    "**Intuition:** Let's measure the distance between the points. <br>\n",
    "Distance feels natural:\n",
    "- If two points are close -> similar\n",
    "- If two points are far  -> different\n",
    "\n",
    "The most common way to calculate distance is to use the **Euclidean distance formula**:\n",
    "$$\\text{Distance}(\\vec{a}, \\vec{b}) = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$$\n",
    "\n",
    "Let's calculate:\n",
    "- Distance(apple, banana) = 0.41 (close) ‚úÖ\n",
    "- Distance(apple, operating system) = 1.5 (far) ‚úÖ\n",
    "\n",
    "This works well initially..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bb1624",
   "metadata": {},
   "source": [
    "###\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92ed8dd",
   "metadata": {},
   "source": [
    "### The Problem with Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "problem",
   "metadata": {},
   "source": [
    "Consider adding a **green apple** at coordinates (0.45, 0.35).\n",
    "\n",
    "Now let's calculate distances:\n",
    "- Distance(apple, banana) = 0.41\n",
    "- Distance(apple, green apple) = 0.57 ‚ùå\n",
    "\n",
    "**Problem:** According to Euclidean distance, an apple is more similar to a banana than to a green apple! This doesn't make semantic sense.\n",
    "\n",
    "**Why?** The green apple lies in the same *direction* as apple, just with smaller magnitude. Distance alone doesn't capture this directional similarity.\n",
    "\n",
    "![Green Apple Problem](../../data/photos/embedding_space_with_green_apple.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba1539",
   "metadata": {},
   "source": [
    "###\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9fd0e8",
   "metadata": {},
   "source": [
    "### The Solution: Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosine_intro",
   "metadata": {},
   "source": [
    "**Cosine similarity** measures the angle between vectors, that is it captures the direction not their distance:\n",
    "\n",
    "$$\\text{cosine\\_similarity}(\\vec{a}, \\vec{b}) = \\frac{\\vec{a} \\cdot \\vec{b}}{||\\vec{a}|| \\times ||\\vec{b}||}$$\n",
    "\n",
    "**Range:** -1 to 1\n",
    "- 1 = identical direction (very similar)\n",
    "- 0 = perpendicular (unrelated)\n",
    "- -1 = opposite direction (opposite meaning)\n",
    "<br>\n",
    "<br>\n",
    " \n",
    "Let us now calculate the cosine similarities:\n",
    "- **Apple & green apple**: cosine(0) ‚âà 1 (indicating extremely high similarity; vectors are in the same direction) ‚úÖ\n",
    "- **Apple & banana**: cosine(20.1¬∞) ‚âà 0.93 (lower than apple & green apple, but still reflecting substantial similarity) ‚úÖ\n",
    "- **Apple & operating system**: cosine(205.6¬∞) ‚âà -0.9 (the vectors point in nearly opposite directions, indicating strong dissimilarity) ‚úÖ\n",
    "\n",
    "\n",
    "This captures the *semantic direction* rather than just magnitude!\n",
    "\n",
    "![](../../data/photos/embedding_space_with_angles.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc71e09",
   "metadata": {},
   "source": [
    "##\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3470be9f",
   "metadata": {},
   "source": [
    "## üß™ Implementation: Let‚Äôs Apply What We Learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "Now that we understand what embeddings are and how they help us measure the similarity between words or sentences, let‚Äôs implement it step by step.\n",
    "\n",
    "In this assignment, you will:\n",
    "1. Choose a few words\n",
    "2. Generate embeddings for each using a pre-trained model\n",
    "3. Compute cosine similarity between the embeddings\n",
    "4. Interpret the results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe349d6",
   "metadata": {},
   "source": [
    "#### Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the embedding model\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "print(f\"Model loaded successfully: {MODEL_NAME}\")\n",
    "print(f\"Model dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e27114",
   "metadata": {},
   "source": [
    "####\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2931c6d1",
   "metadata": {},
   "source": [
    "#### Task 1 - Pick Your Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f159e",
   "metadata": {},
   "source": [
    "Choose at least three words:\n",
    "- Two words that you think are similar\n",
    "- One word that is very different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df87293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example:\n",
    "# words = [\"apple\", \"banana\", \"green apple\", \"syrup\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca387f16",
   "metadata": {},
   "source": [
    "### \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3a2b40",
   "metadata": {},
   "source": [
    "#### Task 2 - Generate Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generate_embeddings",
   "metadata": {},
   "source": [
    "Use any embedding model (e.g., sentence-transformers) to generate dense vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embed_words",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can geneate embeedings in bulk by using the model.encode() method\n",
    "embeddings = model.encode(words)\n",
    "\n",
    "# Let's create a mapping of words to their embeddings\n",
    "embedding_mapping = dict(zip(words, embeddings))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972436f",
   "metadata": {},
   "source": [
    "When we run model.encode, it gives us a numpy array of floats. Basically, each word is turned into a list of numbers, and the length of that list is 384 that's the 'dimension' of our embedding space.\n",
    "So, no matter what word or sentence we give, it's always mapped to a float array of length 384."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bf3087",
   "metadata": {},
   "source": [
    "### \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708e95f",
   "metadata": {},
   "source": [
    "#### Task 3 - Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4808983a",
   "metadata": {},
   "source": [
    "Use the formula discussed earlier or a library function to compute similarities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdab25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the cosine_similarity function. It should take in two arrays and return the cosine similarity between them.\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    raise NotImplementedError(\"You need to implement this function\")\n",
    "    # return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will calculate the cosine similarity between all the words in our embedding_mapping dictionary.\n",
    "# We will store the results in a dictionary called similarity_mapping.\n",
    "similarity_mapping = {}\n",
    "for word1 in embedding_mapping:\n",
    "    for word2 in embedding_mapping:\n",
    "        similarity_mapping[(word1, word2)] = cosine_similarity(embedding_mapping[word1], embedding_mapping[word2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc76b04c",
   "metadata": {},
   "source": [
    "### \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7959ec",
   "metadata": {},
   "source": [
    "#### Task 4 - Analyze the Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df45bf",
   "metadata": {},
   "source": [
    "Answer the following:\n",
    "- Which pair has the highest similarity score?\n",
    "- Does the result match your intuition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c878b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the cosine similarity matrix using a heatmap.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Extract the unique words to form the axes\n",
    "words = sorted(set([key[0] for key in similarity_mapping.keys()]))\n",
    "\n",
    "# Build the square similarity matrix\n",
    "similarity_matrix = np.array([\n",
    "    [similarity_mapping[(w1, w2)] for w2 in words]\n",
    "    for w1 in words\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Create custom colormap for better visual appeal\n",
    "colors = ['#2d5aa6', '#5d8bc7', '#a8c5e8', '#f7f7f7', '#f4a582', '#d6604d', '#b2182b']\n",
    "n_bins = 100\n",
    "cmap = LinearSegmentedColormap.from_list('custom', colors, N=n_bins)\n",
    "\n",
    "# Create figure with modern styling\n",
    "fig, ax = plt.subplots(figsize=(10, 9), facecolor='white')\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Plot the heatmap\n",
    "im = ax.imshow(similarity_matrix, cmap=cmap, vmin=0, vmax=1, aspect='auto', interpolation='nearest')\n",
    "\n",
    "# Customize ticks and labels\n",
    "ax.set_xticks(np.arange(len(words)))\n",
    "ax.set_yticks(np.arange(len(words)))\n",
    "ax.set_xticklabels(words, fontsize=11, fontweight='500', rotation=45, ha='right')\n",
    "ax.set_yticklabels(words, fontsize=11, fontweight='500')\n",
    "\n",
    "# Title styling\n",
    "ax.set_title(\"Cosine Similarity Matrix\", fontsize=18, fontweight='bold', pad=20, color='#2c3e50')\n",
    "\n",
    "# Add grid for better readability\n",
    "ax.set_xticks(np.arange(len(words)) - 0.5, minor=True)\n",
    "ax.set_yticks(np.arange(len(words)) - 0.5, minor=True)\n",
    "ax.grid(which=\"minor\", color=\"white\", linestyle='-', linewidth=2)\n",
    "ax.tick_params(which=\"minor\", size=0)\n",
    "\n",
    "# Add annotations with dynamic text color based on background\n",
    "for i in range(len(words)):\n",
    "    for j in range(len(words)):\n",
    "        value = similarity_matrix[i, j]\n",
    "        # Choose text color based on background intensity\n",
    "        text_color = 'white' if value > 0.6 or value < 0.3 else 'black'\n",
    "        ax.text(j, i, f\"{value:.2f}\", \n",
    "                ha=\"center\", va=\"center\", \n",
    "                color=text_color, \n",
    "                fontsize=10,\n",
    "                fontweight='600')\n",
    "\n",
    "# Enhanced colorbar\n",
    "cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Cosine Similarity', fontsize=12, fontweight='600', color='#2c3e50')\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "# Remove top and right spines for cleaner look\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_color('#bdc3c7')\n",
    "ax.spines['left'].set_color('#bdc3c7')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9219e9",
   "metadata": {},
   "source": [
    "### \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0de46d",
   "metadata": {},
   "source": [
    "#### Task 5 - Complete the Embedding Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9274b",
   "metadata": {},
   "source": [
    "Complete the function below that:\n",
    "- Takes a list of strings\n",
    "- Generates embeddings\n",
    "- Returns them in the same order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text_list):\n",
    "    \"\"\"\n",
    "    Given a list of strings, return their embeddings\n",
    "    in the exact same order as the input.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO:\n",
    "    # 1. Encode the text_list using the model\n",
    "    # 2. Return the embeddings\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af280704",
   "metadata": {},
   "source": [
    "üìå Additional Step - Update the embedding_service.py File\n",
    "\n",
    "Once your get_embeddings function is complete and tested:<br>\n",
    "**Add or update the same function inside** ``embedding_service.py``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0667f2ae",
   "metadata": {},
   "source": [
    "##\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7593805f",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Limitations of Embeddings (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb155840",
   "metadata": {},
   "source": [
    "While embeddings are powerful tools for capturing semantic similarity, they have important limitations that we need to understand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vector_arithmetic",
   "metadata": {},
   "source": [
    "### A Critical Problem with Semantic Similarity\n",
    "\n",
    "One significant limitation is how embeddings handle sentences with **opposite meanings**. Let's explore this with a concrete example.\n",
    "\n",
    "Consider these two sentences:\n",
    "- \"Apple is a fruit\"\n",
    "- \"Apple is not a fruit\"\n",
    "\n",
    "These sentences have **opposite meanings**, yet when we calculate their embeddings and measure similarity, we get surprisingly high similarity scores. Let's see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the embedding model\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "print(f\"Model loaded successfully: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a cosine similarity function\n",
    "def cosine_similarity(vec_a, vec_b):\n",
    "    return np.dot(vec_a, vec_b) / (np.linalg.norm(vec_a) * np.linalg.norm(vec_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Negation Problem: Demonstrating a key limitation of embeddings\n",
    "\n",
    "# Two sentences with opposite meanings\n",
    "sentence1 = \"Apple is a fruit\"\n",
    "sentence2 = \"Apple is not a fruit\"\n",
    "\n",
    "# Generate embeddings\n",
    "embedding1 = model.encode(sentence1)\n",
    "embedding2 = model.encode(sentence2)\n",
    "\n",
    "# Calculate similarity\n",
    "similarity = cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"The Negation Problem\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nSentence 1: '{sentence1}'\")\n",
    "print(f\"Sentence 2: '{sentence2}'\")\n",
    "print(f\"\\nCosine Similarity: {similarity:.4f}\")\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Despite having OPPOSITE meanings, these sentences have\")\n",
    "print(f\"a similarity score of {similarity:.4f}!\")\n",
    "print(f\"\\nWhy? Because they share most of the same words:\")\n",
    "print(f\"  - Both contain: 'apple', 'is', 'a', 'fruit'\")\n",
    "print(f\"  - Only difference: the word 'not'\")\n",
    "print(f\"\\nEmbeddings capture word overlap more than logical meaning.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1971b1",
   "metadata": {},
   "source": [
    "####\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f433b",
   "metadata": {},
   "source": [
    "### Why Does This Happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8111f",
   "metadata": {},
   "source": [
    "Embeddings are based on the **distributional hypothesis**: words that appear in similar contexts tend to have similar meanings. When we embed sentences, the model primarily focuses on:\n",
    "\n",
    "1. **Word Overlap**: Both sentences share most of their words\n",
    "2. **Contextual Patterns**: The sentence structures are nearly identical\n",
    "3. **Token-Level Similarities**: The presence of \"apple\", \"fruit\", etc. dominates\n",
    "\n",
    "The single word \"not\" doesn't change the embedding enough to reflect the complete reversal of meaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3737d0",
   "metadata": {},
   "source": [
    "####\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee907d2b",
   "metadata": {},
   "source": [
    "### Implications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de58c871",
   "metadata": {},
   "source": [
    "This limitation means embeddings may struggle with:\n",
    "- **Negations**: \"good\" vs \"not good\"\n",
    "- **Contradictions**: \"X is Y\" vs \"X is not Y\"  \n",
    "- **Subtle Semantic Differences**: Where a small word change drastically alters meaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c479e3",
   "metadata": {},
   "source": [
    "####\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad95f60",
   "metadata": {},
   "source": [
    "### When Does This Matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0513d3",
   "metadata": {},
   "source": [
    "This limitation is particularly important in:\n",
    "- **Question Answering**: \"Is X true?\" vs \"Is X false?\"\n",
    "- **Fact Verification**: Checking if statements contradict each other\n",
    "- **Sentiment Analysis**: \"I like this\" vs \"I don't like this\"\n",
    "\n",
    "For these use cases, more sophisticated approaches (like cross-encoders or fine-tuned models) may be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98627fc",
   "metadata": {},
   "source": [
    "##\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3fd3bf",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767ad682",
   "metadata": {},
   "source": [
    "### What We Learned:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "1. **Embeddings Transform Words into Vectors**\n",
    "   - Semantic meaning is captured in numerical form\n",
    "   - Similar concepts cluster together in embedding space\n",
    "\n",
    "2. **Cosine Similarity > Euclidean Distance**\n",
    "   - Direction matters more than distance\n",
    "   - Captures semantic relationships more accurately\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aafe4e",
   "metadata": {},
   "source": [
    "####\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e561da5",
   "metadata": {},
   "source": [
    "\n",
    "### Applications:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe294bd0",
   "metadata": {},
   "source": [
    "- üîç **Semantic Search**: Find documents by meaning, not just keywords\n",
    "- üóÇÔ∏è **Clustering**: Group similar items together\n",
    "- üè∑Ô∏è **Classification**: Categorize text automatically\n",
    "- ü§ñ **RAG Systems**: Retrieve relevant context for LLMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde39e7f",
   "metadata": {},
   "source": [
    "##\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
